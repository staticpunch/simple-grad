{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e01898ff-f886-4d09-bf68-e88f7d384b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Define the neural network architecture\n",
    "class DecimalToBinaryNet(nn.Module):\n",
    "    def __init__(self, input_digits, input_classes, hidden_size, output_bits, output_classes):\n",
    "        super(DecimalToBinaryNet, self).__init__()\n",
    "        self.input_size = input_digits * input_classes\n",
    "        self.output_bits = output_bits\n",
    "        self.output_classes = output_classes\n",
    "        \n",
    "        # Flatten input and linear layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layer1 = nn.Linear(self.input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, output_bits * output_classes)\n",
    "        \n",
    "        # For reshaping output\n",
    "        self.output_shape = (-1, output_bits, output_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, decimal_digits, 10)\n",
    "        x = self.flatten(x)  # Flatten to (batch_size, decimal_digits*10)\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        # Reshape to (batch_size, binary_bits, 2)\n",
    "        x = x.view(self.output_shape)\n",
    "        # Apply softmax along the last dimension (class dim)\n",
    "        x = nn.functional.softmax(x, dim=2)\n",
    "        return x\n",
    "\n",
    "# Custom dataset for decimal to binary conversion\n",
    "class DecimalToBinaryDataset(Dataset):\n",
    "    def __init__(self, decimal_range=4096):\n",
    "        self.decimal_range = decimal_range\n",
    "        self.max_bits = int(np.log2(decimal_range)) + 1  # Number of bits needed\n",
    "        self.max_decimal_digits = len(str(decimal_range - 1))  # Max number of decimal digits\n",
    "        self.data = self.generate_data()\n",
    "        \n",
    "    def generate_data(self):\n",
    "        data = []\n",
    "        for i in range(self.decimal_range):\n",
    "            # Convert to one-hot encoded tensors\n",
    "            decimal_str = str(i).zfill(self.max_decimal_digits)\n",
    "            binary_str = format(i, f'0{self.max_bits}b')\n",
    "            \n",
    "            # Create one-hot encoded tensors for decimal digits\n",
    "            decimal_tensor = torch.zeros(self.max_decimal_digits, 10)  # 10 possible values (0-9)\n",
    "            for digit_idx, digit in enumerate(decimal_str):\n",
    "                decimal_tensor[digit_idx, int(digit)] = 1.0\n",
    "                \n",
    "            # Create one-hot encoded tensors for binary digits\n",
    "            binary_tensor = torch.zeros(self.max_bits, 2)  # 2 possible values (0-1)\n",
    "            for bit_idx, bit in enumerate(binary_str):\n",
    "                binary_tensor[bit_idx, int(bit)] = 1.0\n",
    "                \n",
    "            data.append({\"decimal\": decimal_tensor, \"binary\": binary_tensor})\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def get_max_bits(self):\n",
    "        return self.max_bits\n",
    "    \n",
    "    def get_max_decimal_digits(self):\n",
    "        return self.max_decimal_digits\n",
    "\n",
    "# Data utility functions\n",
    "def generate_and_split_data(decimal_range=4096, train_ratio=0.8, batch_size=64):\n",
    "    dataset = DecimalToBinaryDataset(decimal_range=decimal_range)\n",
    "    \n",
    "    # Calculate sizes\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    \n",
    "    # Split the dataset\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader, dataset.get_max_bits(), dataset.get_max_decimal_digits()\n",
    "\n",
    "# Training function\n",
    "def train(model, train_loader, test_loader, criterion, optimizer, num_epochs=10, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            decimal_data = batch[\"decimal\"].to(device)\n",
    "            binary_data = batch[\"binary\"].to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(decimal_data)\n",
    "            loss = criterion(outputs, binary_data)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Print statistics\n",
    "        # print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "        \n",
    "        # Evaluate the model\n",
    "        if epoch % 50 == 0:\n",
    "            # print(outputs.shape, binary_data.shape)\n",
    "            number_accuracy, digit_accuracy = evaluate(model, test_loader, device)\n",
    "            epoch_loss = running_loss / len(train_loader)\n",
    "            print(\n",
    "                f\"Epoch {epoch}: Training loss: {epoch_loss:.4f}, \"\n",
    "                f\"Number accuracy: {number_accuracy:.2f}%, \"\n",
    "                f\"Digit accuracy: {digit_accuracy:.2f}\"\n",
    "            )\n",
    "    \n",
    "    print(\"Training completed!\")\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, test_loader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    num_correct_numbers = 0\n",
    "    num_correct_digits = 0\n",
    "    total_numbers = 0\n",
    "    total_digits = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            decimal_data = batch[\"decimal\"].to(device)\n",
    "            binary_data = batch[\"binary\"].to(device)\n",
    "            \n",
    "            outputs = model(decimal_data)\n",
    "            # Get the index of the highest probability (argmax) for each position\n",
    "            _, predicted_indices = torch.max(outputs, dim=2)\n",
    "            _, target_indices = torch.max(binary_data, dim=2)\n",
    "            \n",
    "            # Count fully correct predictions (all bits must be correct)\n",
    "            num_correct_numbers += (predicted_indices == target_indices).all(dim=1).sum().item()\n",
    "            total_numbers += decimal_data.size(0)\n",
    "            \n",
    "            # Count correct individual digits\n",
    "            num_correct_digits += (predicted_indices == target_indices).sum().item()\n",
    "            total_digits += decimal_data.size(0) * predicted_indices.size(1)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    number_accuracy = 100 * num_correct_numbers / total_numbers\n",
    "    digit_accuracy = 100 * num_correct_digits / total_digits\n",
    "    \n",
    "    return number_accuracy, digit_accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8208d3f9-7c6c-4278-914c-cd0f1f3678f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch 0: Training loss: 0.6870, Number accuracy: 0.24%, Digit accuracy: 65.97\n",
      "Epoch 50: Training loss: 0.4584, Number accuracy: 4.88%, Digit accuracy: 81.95\n",
      "Epoch 100: Training loss: 0.4234, Number accuracy: 12.68%, Digit accuracy: 86.38\n",
      "Epoch 150: Training loss: 0.3926, Number accuracy: 39.02%, Digit accuracy: 92.74\n",
      "Epoch 200: Training loss: 0.3716, Number accuracy: 50.00%, Digit accuracy: 94.45\n",
      "Epoch 250: Training loss: 0.3610, Number accuracy: 53.66%, Digit accuracy: 95.18\n",
      "Epoch 300: Training loss: 0.3544, Number accuracy: 56.10%, Digit accuracy: 95.55\n",
      "Epoch 350: Training loss: 0.3496, Number accuracy: 59.51%, Digit accuracy: 96.06\n",
      "Epoch 400: Training loss: 0.3465, Number accuracy: 62.68%, Digit accuracy: 96.42\n",
      "Epoch 450: Training loss: 0.3436, Number accuracy: 65.37%, Digit accuracy: 96.68\n",
      "Epoch 500: Training loss: 0.3411, Number accuracy: 67.56%, Digit accuracy: 96.90\n",
      "Epoch 550: Training loss: 0.3399, Number accuracy: 70.00%, Digit accuracy: 97.15\n",
      "Epoch 600: Training loss: 0.3393, Number accuracy: 70.49%, Digit accuracy: 97.19\n",
      "Epoch 650: Training loss: 0.3383, Number accuracy: 70.49%, Digit accuracy: 97.19\n",
      "Epoch 700: Training loss: 0.3374, Number accuracy: 70.49%, Digit accuracy: 97.19\n",
      "Epoch 750: Training loss: 0.3370, Number accuracy: 71.71%, Digit accuracy: 97.28\n",
      "Epoch 800: Training loss: 0.3364, Number accuracy: 71.95%, Digit accuracy: 97.30\n",
      "Epoch 850: Training loss: 0.3354, Number accuracy: 72.68%, Digit accuracy: 97.43\n",
      "Epoch 900: Training loss: 0.3354, Number accuracy: 72.93%, Digit accuracy: 97.45\n",
      "Epoch 950: Training loss: 0.3350, Number accuracy: 72.44%, Digit accuracy: 97.41\n",
      "Epoch 1000: Training loss: 0.3353, Number accuracy: 73.17%, Digit accuracy: 97.47\n",
      "Epoch 1050: Training loss: 0.3348, Number accuracy: 73.41%, Digit accuracy: 97.49\n",
      "Epoch 1100: Training loss: 0.3348, Number accuracy: 73.41%, Digit accuracy: 97.49\n",
      "Epoch 1150: Training loss: 0.3347, Number accuracy: 73.17%, Digit accuracy: 97.47\n",
      "Epoch 1200: Training loss: 0.3346, Number accuracy: 73.41%, Digit accuracy: 97.49\n",
      "Epoch 1250: Training loss: 0.3348, Number accuracy: 73.41%, Digit accuracy: 97.49\n",
      "Epoch 1300: Training loss: 0.3347, Number accuracy: 73.41%, Digit accuracy: 97.49\n",
      "Epoch 1350: Training loss: 0.3348, Number accuracy: 73.66%, Digit accuracy: 97.50\n",
      "Epoch 1400: Training loss: 0.3348, Number accuracy: 73.66%, Digit accuracy: 97.50\n",
      "Epoch 1450: Training loss: 0.3346, Number accuracy: 73.41%, Digit accuracy: 97.49\n",
      "Epoch 1500: Training loss: 0.3346, Number accuracy: 73.41%, Digit accuracy: 97.49\n",
      "Epoch 1550: Training loss: 0.3345, Number accuracy: 73.66%, Digit accuracy: 97.50\n",
      "Epoch 1600: Training loss: 0.3347, Number accuracy: 73.66%, Digit accuracy: 97.50\n",
      "Epoch 1650: Training loss: 0.3345, Number accuracy: 73.66%, Digit accuracy: 97.50\n",
      "Epoch 1700: Training loss: 0.3347, Number accuracy: 73.66%, Digit accuracy: 97.50\n",
      "Epoch 1750: Training loss: 0.3349, Number accuracy: 73.66%, Digit accuracy: 97.50\n",
      "Epoch 1800: Training loss: 0.3349, Number accuracy: 73.66%, Digit accuracy: 97.50\n",
      "Epoch 1850: Training loss: 0.3346, Number accuracy: 73.66%, Digit accuracy: 97.50\n",
      "Epoch 1900: Training loss: 0.3346, Number accuracy: 73.90%, Digit accuracy: 97.52\n",
      "Epoch 1950: Training loss: 0.3349, Number accuracy: 73.66%, Digit accuracy: 97.50\n",
      "Training completed!\n",
      "Decimal: 20\n",
      "Binary prediction: 0000000010100\n",
      "Actual binary: 0000000010100\n",
      "Correct: True\n",
      "------------------------------\n",
      "Decimal: 1918\n",
      "Binary prediction: 0011101111110\n",
      "Actual binary: 0011101111110\n",
      "Correct: True\n",
      "------------------------------\n",
      "Decimal: 1219\n",
      "Binary prediction: 0010011000011\n",
      "Actual binary: 0010011000011\n",
      "Correct: True\n",
      "------------------------------\n",
      "Decimal: 184\n",
      "Binary prediction: 0000010111000\n",
      "Actual binary: 0000010111000\n",
      "Correct: True\n",
      "------------------------------\n",
      "Decimal: 2447\n",
      "Binary prediction: 0100110101111\n",
      "Actual binary: 0100110001111\n",
      "Correct: False\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Custom weighted loss function\n",
    "# Define the loss function with class weights\n",
    "def binary_loss(predictions, targets):\n",
    "    # Get target class indices (0 or 1)\n",
    "    target_indices = targets.argmax(dim=2)\n",
    "    \n",
    "    # Calculate standard cross entropy loss\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "    loss = loss_fn(predictions.view(-1, 2), target_indices.view(-1))\n",
    "    loss = loss.view(targets.shape[0], targets.shape[1])\n",
    "    loss = loss.mean()\n",
    "    return loss\n",
    "    \n",
    "def main():\n",
    "    # Set device\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Generate and split data\n",
    "    decimal_range = 4096\n",
    "    train_loader, test_loader, max_bits, max_decimal_digits = generate_and_split_data(\n",
    "        decimal_range=decimal_range,\n",
    "        train_ratio=0.9,\n",
    "        batch_size=256\n",
    "    )\n",
    "    \n",
    "    # Initialize the model\n",
    "    input_digits = max_decimal_digits\n",
    "    input_classes = 10  # 0-9 for decimal digits\n",
    "    hidden_size = 256  # Can be tuned\n",
    "    output_bits = max_bits\n",
    "    output_classes = 2  # 0-1 for binary digits\n",
    "    \n",
    "    model = DecimalToBinaryNet(\n",
    "        input_digits, \n",
    "        input_classes, \n",
    "        hidden_size, \n",
    "        output_bits, \n",
    "        output_classes\n",
    "    )\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    # criterion = nn.CrossEntropyLoss()  # Cross-Entropy Loss for classification\n",
    "    criterion = binary_loss\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=0.04, momentum=0.0, weight_decay=0.0)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Train the model\n",
    "    train(\n",
    "        model, \n",
    "        train_loader, \n",
    "        test_loader, \n",
    "        criterion,\n",
    "        optimizer, \n",
    "        num_epochs=2000, \n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Test multiple random examples from the test set\n",
    "    with torch.no_grad():\n",
    "        # Get a batch from test loader\n",
    "        batch = next(iter(test_loader))\n",
    "        decimal_data = batch[\"decimal\"].to(device)\n",
    "        binary_data = batch[\"binary\"].to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = model(decimal_data)\n",
    "        _, predicted_indices = torch.max(predictions, dim=2)\n",
    "        _, target_indices = torch.max(binary_data, dim=2)\n",
    "        \n",
    "        # Select 5 random samples to display\n",
    "        num_samples = min(5, decimal_data.size(0))\n",
    "        sample_indices = torch.randperm(decimal_data.size(0))[:num_samples]\n",
    "        \n",
    "        for idx in sample_indices:\n",
    "            # Convert one-hot decimal back to number\n",
    "            decimal_digits = decimal_data[idx].argmax(dim=1).cpu().numpy()\n",
    "            decimal_num = int(''.join([str(d) for d in decimal_digits]).lstrip('0') or '0')\n",
    "            \n",
    "            # Get binary prediction and actual binary\n",
    "            binary_pred = ''.join([str(predicted_indices[idx, i].item()) for i in range(max_bits)])\n",
    "            binary_actual = ''.join([str(target_indices[idx, i].item()) for i in range(max_bits)])\n",
    "            \n",
    "            # Print comparison\n",
    "            print(f\"Decimal: {decimal_num}\")\n",
    "            print(f\"Binary prediction: {binary_pred}\")\n",
    "            print(f\"Actual binary: {binary_actual}\")\n",
    "            print(f\"Correct: {binary_pred == binary_actual}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merger2",
   "language": "python",
   "name": "merger2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
